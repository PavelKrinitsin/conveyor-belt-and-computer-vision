{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение модели детектора дефектов транспортерных ленты конвейеров (прямоугольные рамки)"
      ],
      "metadata": {
        "id": "eqNzp_YuUDjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Импорт всех необходимых библиотек (ноутбук запускаю локально)*"
      ],
      "metadata": {
        "id": "ywAOWyLmU2jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U4qeHcSEscVk",
        "outputId": "cb1435ec-8916-4d55-8bd2-147d3bec0756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wiCxnQzOscSw",
        "outputId": "eeeac2b8-126b-4dfe-ae15-8afed44b1ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xRlQzUQIscP2",
        "outputId": "bfd13622-b38b-41f6-e414-afe39d73ffe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.3.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.5.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "acQY3gRKscGQ",
        "outputId": "6d66f93b-ef93-41c2-86d9-230f849130df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dun_6ogksjfz",
        "outputId": "64587867-b23c-4e06-cb5f-48d39435ec6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.66.4)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: colorama in c:\\users\\павел\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee7AIf5eWWBI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "import torchvision.transforms.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import warnings\n",
        "import random\n",
        "from torchvision.transforms import ToTensor, Compose\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, RandomHorizontalFlip, Compose\n",
        "from matplotlib.patches import Rectangle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Загружаю исходные изображения участков лент и их разметку в формате (.xml)*"
      ],
      "metadata": {
        "id": "idE3PHzNVCeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к изображениям\n",
        "#img_path = '/content/images'\n",
        "# Загрузка DataFrame с аннотациями\n",
        "#df = pd.read_csv('/content/new_annotations.csv')\n",
        "# Путь к изображениям\n",
        "img_path = 'AppV/Untitled Folder/images'\n",
        "# Загрузка DataFrame с аннотациями\n",
        "df = pd.read_csv('AppV/Untitled Folder/new_annotations.csv')\n",
        "#df = pd.read_csv('/content/df.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "x-CF0N2VZSuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Функция создания модели обучения на базе предобученной модели Resnet50 (создаем генератор якорей для предсказания bounding boxes объектов)*"
      ],
      "metadata": {
        "id": "6x2Ry3AEWU4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для получения модели обнаружения объектов\n",
        "def get_object_detection_model(num_classes):\n",
        "    backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "    backbone = create_feature_extractor(backbone, return_nodes={\"layer4\": \"0\"})\n",
        "    backbone.out_channels = 2048\n",
        "\n",
        "    rpn_anchor_generator = AnchorGenerator(\n",
        "        sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),)\n",
        "    )\n",
        "\n",
        "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
        "        featmap_names=[\"0\"], output_size=7, sampling_ratio=2\n",
        "    )\n",
        "\n",
        "    model = FasterRCNN(\n",
        "        backbone,\n",
        "        num_classes=num_classes,\n",
        "        rpn_anchor_generator=rpn_anchor_generator,\n",
        "        box_roi_pool=roi_pooler,\n",
        "    )\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "P0r0BR_bXB7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Класс для создания кастомного датасета на основе датафрейма разметки*"
      ],
      "metadata": {
        "id": "TlY__sQCXo6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, df, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.dataframe = df\n",
        "        self.imgs = list(self.dataframe['filename'].unique())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.imgs[idx]\n",
        "        img_path = os.path.join(self.root, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        current_annotations = self.dataframe[self.dataframe['filename'] == img_name]\n",
        "        num_objs = len(current_annotations)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for _, row in current_annotations.iterrows():\n",
        "            boxes.append([row[\"xmin\"], row[\"ymin\"], row[\"xmax\"], row[\"ymax\"]])\n",
        "            labels.append(row[\"class\"])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": image_id, \"area\": area, \"iscrowd\": iscrowd}\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n"
      ],
      "metadata": {
        "id": "My344NDpXM4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Блок классов и функций для трансформаций датасета*"
      ],
      "metadata": {
        "id": "9uytvtdsYpuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Классы преобразований\n",
        "class ComposeTransforms(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for transform in self.transforms:\n",
        "            image, target = transform(image, target)\n",
        "        return image, target\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, image, target):\n",
        "        image = F.to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "class CustomRandomHorizontalFlip(object):\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        if torch.rand(1).item() < self.p:\n",
        "            image = F.hflip(image)\n",
        "            if \"boxes\" in target:\n",
        "                bbox = target[\"boxes\"]\n",
        "                image_width = image.shape[2]  # Assuming image shape is [C, H, W]\n",
        "                bbox[:, [0, 2]] = image_width - bbox[:, [2, 0]]\n",
        "                target[\"boxes\"] = bbox\n",
        "        return image, target\n",
        "\n",
        "# Функция для трансформаций\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(ToTensor())\n",
        "    return Compose(transforms)"
      ],
      "metadata": {
        "id": "6b8vepKsXRF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Определение функции collate_fn, которая позволяет корректно объединить батчи при обработке данных*"
      ],
      "metadata": {
        "id": "8rOcQoY0Yt6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для объединения батчей\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "RsEgmXvAXUC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Функция для балансировки классов датасета*"
      ],
      "metadata": {
        "id": "SwVZNzt9Y3Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для вычисления весов классов\n",
        "def calculate_class_weights(df):\n",
        "    class_counts = df['class'].value_counts().to_dict()\n",
        "    total_counts = sum(class_counts.values())\n",
        "    class_weights = {cls: total_counts / count for cls, count in class_counts.items()}\n",
        "    weights = np.zeros(len(class_counts))\n",
        "    for cls, weight in class_weights.items():\n",
        "        weights[cls] = weight\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "AL2XPRBgYY0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Основная функция обучения модели детекции объектов на изображениях*"
      ],
      "metadata": {
        "id": "6xYVOcdkY_HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "def train_model(num_classes, num_epochs, batch_size, device):\n",
        "    dataset = CustomDataset(img_path, df, transforms=get_transform(train=True))\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
        "\n",
        "    class_weights = calculate_class_weights(df)\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    weights = FasterRCNN_ResNet50_FPN_Weights.COCO_V1\n",
        "    model = fasterrcnn_resnet50_fpn(weights=weights)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        progress_bar = tqdm(data_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "\n",
        "        for images, targets in progress_bar:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            epoch_loss += losses.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1))\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Epoch {epoch + 1} completed with loss {epoch_loss / len(data_loader)}\")\n",
        "\n",
        "    print(\"Training completed.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "uyR14zQTXY7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Выбор устройства для выполнения вычислений*"
      ],
      "metadata": {
        "id": "mcBfVLIKZVdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Основной поток выполнения\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "f4g1yFS3ZJAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Основной блок обучения модели детекции*"
      ],
      "metadata": {
        "id": "kCOSCpkWaBxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Правильное количество классов (включая фоновый класс)\n",
        "num_classes = 3\n",
        "\n",
        "# Обучение модели (например, 10 эпох)\n",
        "num_epochs = 10\n",
        "batch_size = 5\n",
        "model = train_model(num_classes, num_epochs, batch_size, device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16gVhqChZPhO",
        "outputId": "34b45a49-6dcf-424a-fa47-259af904b75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed with loss 0.27409427435625167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed with loss 0.11017622022579114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 completed with loss 0.08927402184123084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 completed with loss 0.06798725260332936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 completed with loss 0.06102835134203945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 completed with loss 0.057962850002305846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 completed with loss 0.055938851176982836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 completed with loss 0.055427752945217346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 completed with loss 0.055741946501213877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                                                                                                                                                                                                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 completed with loss 0.055269097887156976\n",
            "Training completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Тестирование модели**"
      ],
      "metadata": {
        "id": "vKamd-NwhvCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Функция визуализации объектов на тестовой выборке изображений (результат работы модели)*"
      ],
      "metadata": {
        "id": "pvWGOfFxZZQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(image, boxes, labels, scores, threshold=0.5):\n",
        "    def generate_color_map(all_labels):\n",
        "        color_map = {}\n",
        "        random.seed(42)  # For reproducibility\n",
        "        for label in all_labels:\n",
        "            color_map[int(label)] = (random.random(), random.random(), random.random())\n",
        "        return color_map\n",
        "\n",
        "    # Печать всех уникальных меток для отладки\n",
        "    unique_labels = np.unique(labels)\n",
        "    print(f\"Unique labels in batch: {unique_labels}\")\n",
        "\n",
        "    color_map = generate_color_map([0, 1, 2])\n",
        "    print(f\"Generated color_map keys: {list(color_map.keys())}\")\n",
        "\n",
        "    drawn_boxes = {label: [] for label in np.unique(labels)}\n",
        "\n",
        "    image = image.permute(1, 2, 0).cpu().numpy()\n",
        "    image = np.clip(image, 0, 1)\n",
        "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score >= threshold:\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            box_coords = (xmin, ymin, xmax, ymax)\n",
        "\n",
        "            intersects = False\n",
        "            for drawn_box in drawn_boxes[label]:\n",
        "                if (xmin < drawn_box[2] and xmax > drawn_box[0] and ymin < drawn_box[3] and ymax > drawn_box[1]):\n",
        "                    intersects = True\n",
        "                    break\n",
        "\n",
        "            if not intersects:\n",
        "                # Оповещение о метке для отладки\n",
        "                print(f\"Drawing box for label: {label} with confidence score: {score}\")\n",
        "\n",
        "                rect = Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=color_map[int(label)], linewidth=2)\n",
        "                ax.add_patch(rect)\n",
        "                label_text = f\"{label}: {score:.2f}\"\n",
        "                ax.text(xmin, ymin, label_text, bbox={\"facecolor\": \"yellow\", \"alpha\": 0.5})\n",
        "\n",
        "                drawn_boxes[label].append(box_coords)\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "x05XiTqbXd8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция оценки работы модели на валидационных данных"
      ],
      "metadata": {
        "id": "06j_S1Y6iBcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка модели на валидационных данных\n",
        "def evaluate_model(model, data_loader_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader_test:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "\n",
        "            for img, output in zip(images, outputs):\n",
        "                boxes = output['boxes'].cpu().numpy()\n",
        "                labels = output['labels'].cpu().numpy()\n",
        "                scores = output['scores'].cpu().numpy()\n",
        "                visualize_predictions(img, boxes, labels, scores)"
      ],
      "metadata": {
        "id": "pbdDFpj6ZGI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Создание валидационного датасета*"
      ],
      "metadata": {
        "id": "e_0sZVTWiaBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка модели на валидационных данных\n",
        "validate_dataset = CustomDataset(img_path, df, transforms=get_transform(train=False))\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    validate_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
        ")\n",
        "evaluate_model(model, data_loader_test)"
      ],
      "metadata": {
        "id": "JYvdUc3DZmLu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Заключение**"
      ],
      "metadata": {
        "id": "aMPv5lC2ipQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель уверенно распознает объекты 1 и 2 класса на изображениях, что может быть использовано для создания автоматизированного комплекса по детекции дефектов поточно-транспортного оборудования промышленных предприятий: ленточных конвейеров различной протяженности.\n",
        "\n",
        "Вопросы, требующие доработки: не распознается класс 0 на объектах - порывы лент."
      ],
      "metadata": {
        "id": "Xa6T_OfpitM9"
      }
    }
  ]
}